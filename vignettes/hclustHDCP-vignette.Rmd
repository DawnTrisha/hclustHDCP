---
title: "Cluster Based High Dimensional Change-point Detection"
author: "Trisha Dawn"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Cluster Based High Dimensional Change-point Detection}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(hclustHDCP)
```
# Objective

In this vignette for the package **hclustHDCP** we will illustrate the importance of the method and the use of the package.

# Introduction

Change-point detection is a classical problem in statistics and machine learning which refers to detecting abrupt significant changes in the probability distribution of a sequence of observations arranged chronologically. There could be single change-point or multiple change-points in the sequence of observations where the observations may be univariate, multivariate, networks or even functional in nature. Clustering can be incorporated in an attempt to detect change-points because we can think of existence of clusters in the observation sequence based on the change-point locations. More precisely, if there is a change-point $1< \tau < n$ in an observed sequence of observations $\{x_1, x_2, \dots, x_n\}$, then there are two clusters, namely, $\{x_1, x_2, \dots, x_{\tau}\}$ and $\{x_{\tau + 1}, x_{\tau + 2}, \dots, x_n\}$. 

This package uses hierarchical clustering based on linkage methods to solve the problem of finding change-point locations. The following example illustrates how change-point detection can be viewed as clustering problem. This example deals with two change-points for $p = 20$ dimensional normal observations differing in their location vector before and after change-points. We consider total $24$ observations among which first $8$ observations come from $N_{20}(\mathbf{0}_{20},I_{20})$, next $8$ observations from $N_{20}(3\mathbf{1}_{20},I_{20})$ and the final $8$ observations from $N_{20}(6\mathbf{1}_{20}, I_{20})$. We use hierarchical clustering with average linkage which classifies the observations into three groups according to the occurrence of the change-points. Note that since observations are high dimensional, for easy visual interpretation we considered clustering the first principal component scores and plot based on those.  


```{r}
# Generating data matrix having change-points at 8 and 16
# Number of observations, n = 24 and dimension, p = 20
set.seed(1)
X1 = matrix(rnorm(8*20, mean = 0, sd = 1), nrow = 8, ncol = 20)
X2 = matrix(rnorm(8*20, mean = 3, sd = 1), nrow = 8, ncol = 20)
X3 = matrix(rnorm(8*20, mean = 6, sd = 1), nrow = 8, ncol = 20)
X = rbind(X1, X2, X3)

# Extracting first PC
X.pca  = prcomp(X, center = T, scale. = T)
M = X.pca$x[ , 1]



# Performing hierarchical clustering 
cl = cutree(hclust(dist(X), method="average"), k=3)
# Observe we get exactly 3 clusters divided by the change-point locations 
cl
which(cl == 1)
which(cl == 2)
which(cl == 3)
```
```{r, echo=FALSE}
z1 = as.vector(which(cl == 1))
z2 = as.vector(which(cl == 2))
z3 = as.vector(which(cl == 3))
y1 = NA
y2 = NA
y3 = NA
y1[z1] = -8
y2[z2] = -8
y3[z3] = -8

v1 = NA
v2 = NA
v3 = NA
v1[z1] = M[z1]
v2[z2] = M[z2]
v3[z3] = M[z3]
```

```{r fig1, fig.height=3, fig.width=6, fig.align="center"}
par(mfrow = c(1, 2))
# Plot of 1st PC of raw data arranged chronologically 
plot(M, pch = 1, xlim = c(1,24), ylim = c(-8,8),
     xlab = "t", ylab = expression(paste("PC"[1])), 
     axes = F,
     frame.plot = F, main = expression(paste("(a) ", " Before Clustering")))
axis(side = 1, at = c(1,8,16,24), tck = -0.03)
axis(side = 2, at = c(-8,0,8), las = 2, tck = -0.03)
box()

# Plot of 1st PC after clustering (clusters are denoted by red, blue and green)
plot(y1, pch = 16, xlim = c(1,24), ylim = c(-8,8),
     xlab = "t", ylab = expression(paste("PC"[1])), 
     axes = F,
     frame.plot = F, col = "red", main = expression(paste("(b) ", "Average Linkage")))
axis(side = 1, at = c(1,8,16,24),tck = -0.03)
axis(side = 2, at = c(-8,0,8), las = 2, tck = -0.03)
points(y2, pch = 16, col = "blue")
points(y3, pch = 16, col = "green")
points(v1, pch = 16, col = "red")
points(v2, pch = 16, col = "blue")
points(v3, pch = 16, col = "green")
box()
```

Clearly clustering can be used for change-point detection as illustrated through the above example. However, if instead of the previous example, we consider that there are same change in location for the observations but now there is only interval change. Specifically, we consider total $24$ observations among which first $8$ observations come from $N_{20}(\mathbf{0}_{20},I_{20})$, next $8$ observations from $N_{20}(3\mathbf{1}_{20},I_{20})$ and the final $8$ observations again from $N_{20}(0\mathbf{1}_{20}, I_{20})$. Now the application of clustering algorithm directly yields the following result.

```{r}
# Generating Data with change-points at t = 8 and t = 16
set.seed(1)
X1 = matrix(rnorm(8*20, mean = 0, sd = 1), nrow = 8, ncol = 20)
X2 = matrix(rnorm(8*20, mean = 3, sd = 1), nrow = 8, ncol = 20)
X3 = matrix(rnorm(8*20, mean = 0, sd = 1), nrow = 8, ncol = 20)
X = rbind(X1, X2, X3)

# Extracting first PC
X.pca  = prcomp(X, center = T, scale. = T)
M = X.pca$x[ , 1]

#par(mar=c(3.75,3.4,2,1),mgp=c(2.3,0.5,0),oma=c(0.5,0.5,0.5,0.5),mfrow=c(2,2))

# Clusters obtained 
cl = cutree(hclust(dist(X), method="average"), k=3)
cl
which(cl == 1)  # Observations in 1st cluster
which(cl == 2)  # Observations in 2nd cluster
which(cl == 3)  # Observations in 3rd cluster
```
```{r, echo=FALSE}
z1 = as.vector(which(cl==1))
z2 = as.vector(which(cl==2))
z3 = as.vector(which(cl==3))
y1 = NA
y2 = NA
y3 = NA
y1[z1] = -8
y2[z2] = -8
y3[z3] = -8

v1 = NA
v2 = NA
v3 = NA
v1[z1] = M[z1]
v2[z2] = M[z2]
v3[z3] = M[z3]
```

```{r, fig2, fig.height=3, fig.width=6, fig.align="center"}
par(mfrow = c(1, 2))
plot(M, pch = 1, xlim = c(1,24), ylim = c(-8,8),
     xlab = "t", ylab = expression(paste("PC"[1])),
     axes = F,
     frame.plot = F, main = expression(paste("(a) ", " Before Clustering")))
axis(side = 1, at = c(1,8,16,24), tck = -0.03)
axis(side = 2, at = c(-8,0,8), las = 2, tck = -0.03)
box()

plot(y1, pch = 16, xlim = c(1,24), ylim = c(-8,8),
     xlab = "t", ylab = expression(paste("PC"[1])),
     axes = F,
     frame.plot = F, col = "red", main = expression(paste("(b) ", "Average Linkage")))
axis(side = 1, at = c(1,8,16,24),tck = -0.03)
axis(side = 2, at = c(-8,0,8), las = 2, tck = -0.03)
points(y2, pch = 16, col = "blue")
points(y3, pch = 16, col = "green")
points(v1, pch = 16, col = "red")
points(v2, pch = 16, col = "blue")
points(v3, pch = 16, col = "green")
box()
```

Clearly if we consider those points as change-point locations where the cluster membership changes for the observations, then we will not be able to detect change-point locations correctly. Hence we introduce consecutive clustering to detect the change-points. For the given example, using our algorithm, we get the following result.
```{r}
detect_multiple_cp(X = X, numcp = 2, dist.method = "average")
```

Hence we get the correct change-point locations when we use consecutive clustering. When the number of change-points are known, we can use **detect_single_cp** or **detect_multiple_cp** functions depending upon whether we want to detect a single change-point or multiple change-points. Here are two examples illustrating the use of those two functions. 

**Single Change-point detection**

Consider $n = 30$ observations of dimension $p = 150$ (high dimensional low sample size setup) arranged chronologically. We consider that first $10$ observations are from $N_{150}(\mathbf{0}_{150}, \mathbf{I}_{150})$ and the remaining $20$ observations are from $N_{150}(\mathbf{1}_{150}, \mathbf{I}_{150})$. Hence in this example, the change occurs as change in location and we also consider that we know there is *only one change-point*.

```{r}
# Example 1  
set.seed(1)
# Generating data, n = 30, p = 150, change-point location at 10
X1 = matrix(rnorm(10 * 150, mean = 0, sd = 1), nrow = 10, ncol = 150)
X2 = matrix(rnorm(20 * 150, mean = 1, sd = 1), nrow = 20, ncol = 150)
X = rbind(X1, X2)

# Finding change-point location using complete linkage 
detect_single_cp(X = X, dist.method = "complete")

# We could also supply the distance matrix instead of data matrix
D_mat = as.matrix(stats::dist(X, method = "euclidean"))

detect_single_cp(D = D_mat, dist.method = "complete")
```

Observe that we get the same result in both cases. Here the true change-point is not at the middle of the time sequence and we used complete linkage. 

Now we illustrate the use of function **detect_multiple_cp**. Here we again consider change in normal locations for a total of $n = 30$ observations having dimension $p = 150$. The first $10$ observations are from $N_{150}(\mathbf{0}_{150}, \mathbf{I}_{150})$, next $10$ observations are from $N_{150}(\mathbf{5}_{150}, \mathbf{I}_{150})$ and the last $10$ observations from $N_{150}(\mathbf{0.2}_{150}, \mathbf{I}_{150})$. We note that although here the observations are coming from different distributions, the mean of the observations from the first cluster $(x_1,\dots,x_{10})$ and last cluster $(x_21,\dots,x_{30})$   are very close. So here consecutive clustering works to detect the change-points when the number of change-points to detect is known as $2$.

```{r}
# Example 2  
set.seed(1)
# Generating data, n = 30, p = 150, change-point locations at 10 and 20
X1 = matrix(rnorm(10 * 150, mean = 0, sd = 1), nrow = 10, ncol = 150)
X2 = matrix(rnorm(10 * 150, mean = 5, sd = 1), nrow = 10, ncol = 150)
X3 = matrix(rnorm(10 * 150, mean = 0.2, sd = 1), nrow = 10, ncol = 150)
X = rbind(X1, X2, X3)

# Finding change-point location with default average linkage and numcp as 2
detect_multiple_cp(X = X, numcp = 2)

# We could also supply the distance matrix instead of data matrix
D_mat = as.matrix(stats::dist(X, method = "euclidean"))

detect_multiple_cp(X = X, numcp = 2)

# We could also supply any number of change-points to detect (1 < numcp < n)
# Finding change-point location with single linkage and numcp as 4
detect_multiple_cp(X = X, numcp = 4, dist.method = "single")
```

We observe that the correct change-point locations are obtained when *numcp* is supplied as $2$. However, if we do not have knowledge about the number of change-points to detect, then we will obtain incorrect change-point locations. In reality almost every situation requires first the estimation of number of change-point then estimation of change-point locations.  
